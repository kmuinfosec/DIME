{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os, math, time, sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "from datetime import datetime\n",
    "from core.utils import savepkl, loadpkl, calculate_metrics\n",
    "from core.conversion import make_whitelist, multiple_ngram\n",
    "from core.selection import make_graph, get_representatives\n",
    "from core.clustering import clustering\n",
    "from core.generation import make_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = configparser.ConfigParser()\n",
    "properties.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_path = properties.get('PATH', 'string_path')\n",
    "label_path = properties.get('PATH', 'label_path')\n",
    "train_path = properties.get('PATH', 'train_path')\n",
    "test_path = properties.get('PATH', 'test_path')\n",
    "\n",
    "save_path = properties.get('PATH', 'save_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = properties.getint('DIME', 'N')\n",
    "thetaB = properties.getint('DIME', 'thetaB')\n",
    "thetaM = properties.getint('DIME', 'thetaM')\n",
    "thetaD = properties.getint('DIME', 'thetaD')\n",
    "eps = properties.getfloat('DIME', 'eps')\n",
    "min_samples = properties.getint('DIME', 'min_samples')\n",
    "Rc = properties.getfloat('DIME', 'Rc')\n",
    "Rd = properties.getfloat('DIME', 'Rd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strings = loadpkl(string_path)\n",
    "data_labels = loadpkl(label_path)\n",
    "train = loadpkl(train_path)\n",
    "test = loadpkl(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_malware = [key for key in train if data_labels[key] != 'benign']\n",
    "train_benign = [key for key in train if data_labels[key] == 'benign']\n",
    "test_malware = [key for key in test if data_labels[key] != 'benign']\n",
    "test_benign = [key for key in test if data_labels[key] == 'benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating whitelist:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating whitelist: 100%|██████████| 80/80 [00:00<00:00, 357.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_benign_string = [data_strings[key] for key in train_benign]\n",
    "whitelist = make_whitelist(train_benign_string, N=N, thetaB=thetaB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = set(data_labels.values()) - {'benign'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gafgyt', 'mirai', 'miraia'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 297 ms\n",
      "Wall time: 609 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for label in train_labels:\n",
    "    train_string = [data_strings[key] for key in train_malware if data_labels[key] == label]\n",
    "    train_size = len(train_string)\n",
    "    \n",
    "    train_ngrams = set()\n",
    "    for strings in train_string:\n",
    "        train_ngrams |= multiple_ngram(strings, N=N)\n",
    "    train_ngrams -= whitelist\n",
    "    \n",
    "    file_ngram = []\n",
    "    for strings in train_string:\n",
    "        file_ngram.append(multiple_ngram(strings) - whitelist)\n",
    "        \n",
    "    graph_path = save_path + f'graph/{label.replace(\"/\", \".\")}_{N}_{thetaB}.pkl'\n",
    "    bipartite_graph = make_graph(train_string, train_ngrams, graph_path, N)\n",
    "   \n",
    "    representatives_path = save_path + f'representatives/{label.replace(\"/\", \".\")}_{N}_{thetaB}_{thetaD}_{thetaM}.pkl'\n",
    "    representatives = get_representatives(bipartite_graph, train_size, thetaD=thetaD, thetaM=thetaM)\n",
    "    savepkl(representatives_path, representatives)\n",
    "    \n",
    "    cluster_path = save_path + f'cluster/{label.replace(\"/\", \".\")}_{N}_{thetaB}_{thetaD}_{thetaM}_{eps}_{min_samples}.pkl'\n",
    "    bipartite_graph = make_graph(train_string, train_ngrams, graph_path, N)\n",
    "    cluster_labels, wordset = clustering(bipartite_graph, representatives, train_size, eps=eps, min_samples=min_samples)\n",
    "    savepkl(cluster_path, (cluster_labels, wordset))\n",
    "    \n",
    "    signature_path = save_path + f'signature/{label.replace(\"/\", \".\")}_{N}_{thetaB}_{thetaD}_{thetaM}_{eps}_{min_samples}_{Rc}.pkl'\n",
    "    signatures = make_signature(file_ngram, cluster_labels, Rc, whitelist)\n",
    "    savepkl(signature_path, signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_benign_ngrams = []\n",
    "test_benign_strings = [data_strings[key] for key in test_benign]\n",
    "for strings in test_benign_strings:\n",
    "    test_benign_ngrams.append(multiple_ngram(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_malware_ngrams = []\n",
    "test_malware_strings = [data_strings[key] for key in test_malware]\n",
    "for strings in test_malware_strings:\n",
    "    test_malware_ngrams.append(multiple_ngram(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_result = []\n",
    "\n",
    "signatures = []\n",
    "for label in train_labels:\n",
    "    signatures_path = save_path + f'signature/{label.replace(\"/\", \".\")}_{N}_{thetaB}_{thetaD}_{thetaM}_{eps}_{min_samples}_{Rc}.pkl'\n",
    "    if not os.path.exists(signatures_path):\n",
    "        print(f\"{label}'s signature not exists\")\n",
    "        continue\n",
    "    signatures.append(loadpkl(signatures_path))\n",
    "\n",
    "tp = tn = fp = fn = 0\n",
    "for ngrams in test_malware_ngrams:\n",
    "    pred = False\n",
    "    for signature in signatures:\n",
    "        for sig_info in signature:\n",
    "            sig = set(sig_info[1][0])\n",
    "\n",
    "            if len(sig)==0:\n",
    "                continue\n",
    "\n",
    "            if int(math.ceil(len(sig)*Rd)) <= len(ngrams&sig):\n",
    "                pred = True\n",
    "                break\n",
    "        if pred:\n",
    "            break\n",
    "    if pred==True:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "for idx, ngrams in enumerate(test_benign_ngrams):\n",
    "    pred = False\n",
    "    for signature in signatures:\n",
    "        for sig_info in signature:\n",
    "            sig = set(sig_info[1][0])\n",
    "\n",
    "            if len(sig)==0:\n",
    "                continue\n",
    "\n",
    "            if int(math.ceil(len(sig)*Rd)) <= len(ngrams&sig):\n",
    "                pred = True\n",
    "                break\n",
    "        if pred:\n",
    "            break\n",
    "    if pred==True:\n",
    "        fp += 1\n",
    "    else:\n",
    "        tn += 1\n",
    "\n",
    "row = [N, thetaD, thetaM, eps, Rc, Rd, tp, tn, fp, fn]\n",
    "test_result.append(row)\n",
    "                    \n",
    "test_result = pd.DataFrame(test_result)\n",
    "test_result.columns = ['N', 'thetaD', 'thetaM', 'eps', 'Rc', 'Rd', 'tp', 'tn', 'fp', 'fn']\n",
    "test_result[['acc.', 'pre.', 'rec.', 'f1-score']] = test_result.apply(calculate_metrics, axis=1)\n",
    "\n",
    "timestamp = time.time()\n",
    "datetime_obj = datetime.fromtimestamp(timestamp)\n",
    "datetime_str = datetime_obj.strftime(\"%Y%m%d%H%M%S\")\n",
    "test_result.to_csv(f'./test_result_{datetime_str}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
